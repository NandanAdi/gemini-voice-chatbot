// src/server.js (Gemini â†’ OpenAI â†’ Cohere fallback)
require('dotenv').config();
const express = require('express');
const http = require('http');
const WebSocket = require('ws');
const axios = require('axios');

const app = express();
const server = http.createServer(app);
const wss = new WebSocket.Server({ server });

app.use(express.static("public"));

const GEMINI_API_KEY = process.env.GEMINI_API_KEY;
const OPENAI_API_KEY = process.env.OPENAI_API_KEY;
const COHERE_API_KEY = process.env.COHERE_API_KEY;

const GEMINI_MODEL = "gemini-2.0-flash-live-001"; // Live model
const GEMINI_LIVE_URL = `wss://generativelanguage.googleapis.com/v1beta/live?key=${GEMINI_API_KEY}`;

const OPENAI_API_URL = "https://api.openai.com/v1/chat/completions";
const COHERE_API_URL = "https://api.cohere.ai/v1/chat";

wss.on("connection", (clientWs) => {
  console.log("ğŸŒ Client connected");

  let geminiWs;

  try {
    // ğŸ”— Connect to Gemini Live WebSocket
    geminiWs = new WebSocket(GEMINI_LIVE_URL);

    geminiWs.on("open", () => {
      console.log("âœ… Connected to Gemini Live API");

      // Tell Gemini which model to use
      geminiWs.send(
        JSON.stringify({
          setup: { model: GEMINI_MODEL },
        })
      );
    });

    // Forward Geminiâ€™s responses back to the browser
    geminiWs.on("message", (data) => {
      try {
        const msg = JSON.parse(data.toString());
        const text = msg.candidates?.[0]?.content?.parts?.[0]?.text;

        // ğŸš« Ignore system/init responses
        if (!text || text.toLowerCase().includes("gemini live")) return;

        console.log("ğŸ¤– Gemini Live:", text);
        if (clientWs.readyState === WebSocket.OPEN) {
          clientWs.send(JSON.stringify({ text, source: "Gemini" }));
        }
      } catch (err) {
        console.error("Parse error from Gemini Live:", err);
      }
    });

    geminiWs.on("error", (err) => {
      console.error("ğŸš¨ Gemini Live error:", err.message);
    });

    // When browser sends a message â†’ forward to Gemini
    clientWs.on("message", (msg) => {
      const userText = msg.toString().trim();

      // ğŸš« Ignore empty/blank messages
      if (!userText) {
        console.log("âš ï¸ Ignored empty message");
        return;
      }

      console.log("ğŸ“ User said:", userText);

      if (geminiWs.readyState === WebSocket.OPEN) {
        geminiWs.send(
          JSON.stringify({
            input: { text: userText },
          })
        );
      } else {
        console.log("âš ï¸ Gemini WS not open, using fallback...");
        fallbackToOtherModels(clientWs, userText);
      }
    });
  } catch (err) {
    console.error("ğŸš¨ Could not connect to Gemini Live:", err.message);
  }

  clientWs.on("close", () => {
    if (geminiWs && geminiWs.readyState === WebSocket.OPEN) {
      geminiWs.close();
    }
    console.log("âŒ Client disconnected");
  });
});

/**
 * Fallback to OpenAI â†’ Cohere if Gemini Live fails
 */
async function fallbackToOtherModels(ws, userText) {
  let finalText = "âŒ Could not get a response.";
  let source = "Unknown";

  // 1ï¸âƒ£ Try OpenAI
  try {
    const openaiResp = await axios.post(
      OPENAI_API_URL,
      {
        model: "gpt-3.5-turbo",
        messages: [
          {
            role: "system",
            content:
              "You are Revolt Motorsâ€™ AI Assistant. Be polite, concise, and only answer about Revolt Motors, its EV products, general EV info, and small talk. ğŸš« Never mention APIs, quotas, or errors.",
          },
          { role: "user", content: userText },
        ],
      },
      {
        headers: {
          "Content-Type": "application/json",
          Authorization: `Bearer ${OPENAI_API_KEY}`,
        },
      }
    );

    finalText =
      openaiResp.data.choices?.[0]?.message?.content ||
      "âŒ OpenAI returned no text.";
    source = "OpenAI";
    console.log("ğŸ¤– OpenAI response:", finalText);
  } catch (err) {
    console.error("ğŸš¨ OpenAI error:", err.response?.data || err.message);

    // 2ï¸âƒ£ Try Cohere
    try {
      const cohereResp = await axios.post(
        COHERE_API_URL,
        {
          model: "command-r-plus", // free tier model
          message: userText,
          chat_history: [
            {
              role: "SYSTEM",
              message:
                "You are Revolt Motorsâ€™ AI Assistant. Always be polite and concise. Only talk about Revolt Motors, its EV products, general EV info, and polite small talk. ğŸš« Never mention APIs, quotas, or errors. If you donâ€™t know, say: 'Iâ€™m not sure about that, but I can help you with Revolt Motors or EV questions.'",
            },
          ],
        },
        {
          headers: {
            "Content-Type": "application/json",
            Authorization: `Bearer ${COHERE_API_KEY}`,
          },
        }
      );

      finalText =
        cohereResp.data?.text ||
        "âŒ Cohere returned no text.";
      source = "Cohere";

      console.log("ğŸ¤– Cohere response:", finalText);
    } catch (cohereError) {
      console.error(
        "ğŸš¨ Cohere error:",
        cohereError.response?.data || cohereError.message
      );
      finalText = "âŒ All providers failed (Gemini, OpenAI, Cohere).";
      source = "None";
    }
  }

  if (ws.readyState === WebSocket.OPEN) {
    ws.send(JSON.stringify({ text: finalText, source }));
  }
}

const PORT = process.env.PORT || 3000;
server.listen(PORT, () => {
  console.log(`ğŸš€ Server running on http://localhost:${PORT}`);
  if (!GEMINI_API_KEY) console.error("âŒ Missing GEMINI_API_KEY in .env file");
});
